{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 00:20:54.886950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 00:20:55.063021: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-01 00:20:55.064092: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 00:20:56.097876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, Flatten, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import albumentations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "WIDTH = 224\n",
    "HEIGHT = 224 \n",
    "BATCH_SIZE = 32\n",
    "TEST_SPLIT = 0.2\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4247, 2) (1062, 2)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "with open(\"bboxes.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Get data and transform left hand labels to 0 and right hand labels to 1\n",
    "df = pd.DataFrame.from_dict(data).T\n",
    "label_names = ['palmar left', 'palmar right']\n",
    "df.replace(label_names , [0, 1], inplace=True)\n",
    "\n",
    "# # Count the number of left and right hands in the data\n",
    "# labels = df[\"label\"].value_counts()\n",
    "# print(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(df, test_size=TEST_SPLIT)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "train_images, train_bboxes, train_labels = train.index.to_numpy(), train[\"bbox\"].to_numpy(), train[\"label\"].to_numpy()\n",
    "test_images, test_bboxes, test_labels = test.index.to_numpy(), test[\"bbox\"].to_numpy(), test[\"label\"].to_numpy()\n",
    "\n",
    "train_labels = np_utils.to_categorical(train_labels, 2)\n",
    "test_labels = np_utils.to_categorical(test_labels, 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "### 2.1 Resizing & Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, bbox, label):\n",
    "    \n",
    "    filename = path.decode(\"utf-8\")\n",
    "    path = f\"data/{filename}\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    transform = albumentations.Compose(\n",
    "        [albumentations.Resize(height=HEIGHT, width=WIDTH, always_apply=True)],\n",
    "        bbox_params=albumentations.BboxParams(format='coco'))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=[np.concatenate([bbox,[0]])])\n",
    "    image, bbox = transformed[\"image\"], transformed[\"bboxes\"][0]\n",
    "\n",
    "    # cv2.circle(image,(int(bbox[0]),int(bbox[1])), 2, (0,255,0), -1)\n",
    "    # cv2.circle(image,(int(bbox[0])+int(bbox[2]),int(bbox[1])+int(bbox[3])), 2, (0,255,0), -1)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "    \n",
    "    norm_image = tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "    x1, y1, x2, y2 = bbox[0]/WIDTH, bbox[1]/HEIGHT, bbox[2]/WIDTH, bbox[3]/HEIGHT\n",
    "    norm_bbox = np.array([x1, y1, x2, y2], dtype=np.float32)\n",
    "\n",
    "    return norm_image, norm_bbox, label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3) (5, 4) (5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 01:57:30.298347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [4247,2]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "def parse(image, bbox, label):\n",
    "    image, bbox, label = tf.numpy_function(read_image, [image, bbox, label], [tf.float32, tf.float32, tf.float32])\n",
    "    image.set_shape((WIDTH, HEIGHT, 3))\n",
    "    bbox.set_shape((4))\n",
    "    label.set_shape((2))\n",
    "    return image, bbox, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, list(train_bboxes), train_labels))\n",
    "train_dataset = train_dataset.map(parse).batch(5)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, list(test_bboxes), test_labels))\n",
    "test_dataset = test_dataset.map(parse).batch(5)\n",
    "\n",
    "for X, bbox, label  in train_dataset:\n",
    "    print(X.shape, bbox.shape, label.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
