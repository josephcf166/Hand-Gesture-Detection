{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, Flatten, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model \n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import huber_loss\n",
    "from models.model import DARKNET19_ARCHITECTURE, INPUT_SIZE, build_model\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.utils import np_utils\n",
    "import albumentations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "WIDTH = 448\n",
    "HEIGHT = 448 \n",
    "BATCH_SIZE = 8\n",
    "TEST_SPLIT = 0.2\n",
    "LEARNING_RATE = 5e-3\n",
    "EPOCHS = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"bboxes.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# data = {}\n",
    "\n",
    "# for i in os.listdir(\"labels/\"):\n",
    "#     with open(f\"labels/{i}\") as f:\n",
    "#         temp = []\n",
    "#         for line in f:\n",
    "#             temp.append(line.split()[4:8])\n",
    "#         if(len(temp) == 4):\n",
    "#             labels = temp\n",
    "#         else:\n",
    "#             labels = []\n",
    "        \n",
    "#         if(labels != []):\n",
    "#             i = i.split(\".\")[0] + \".jpg\"\n",
    "#             data[i] = {}\n",
    "\n",
    "#             for _ in range(2):\n",
    "#                 labels.pop(0)\n",
    "\n",
    "#             data[i] = [int(labels[0][0]), int(labels[0][1]), int(labels[0][2]), int(labels[0][3])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "dataset_path = \"multiview_hand_pose_dataset_release\"\n",
    "for dir in os.listdir(dataset_path):\n",
    "    for i in range(100):\n",
    "        for j in range(4):\n",
    "            bbox = []\n",
    "            try:\n",
    "                with open(f\"{dataset_path}/{dir}/{i}_bbox_{j+1}.txt\", \"r\") as f:\n",
    "                    for line in f:\n",
    "                        bbox.append(int(line.split(\" \")[1].strip(\"\\n\")))\n",
    "                bbox[0], bbox[1] = bbox[1], bbox[0]\n",
    "                bbox[2], bbox[3] = bbox[3], bbox[2]\n",
    "                data[f\"{dir}\\{i}_webcam_{j+1}.jpg\"] = bbox\n",
    "            except: \n",
    "                continue\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# for file in data:\n",
    "#     bbox = data[file]\n",
    "\n",
    "#     image = cv2.imread(f\"{dataset_path}\\{file}\")\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255,0,0), 2)\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and transform left hand labels to 0 and right hand labels to 1\n",
    "df = pd.DataFrame({\"filename\": [], \"bbox\": []})\n",
    "for filename in data:\n",
    "    df.loc[len(df)] = [filename, data[filename]]\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(df, test_size=TEST_SPLIT, shuffle=False)\n",
    "\n",
    "train_images, train_bboxes = train[\"filename\"].to_numpy(), train[\"bbox\"].to_numpy()\n",
    "test_images, test_bboxes = test[\"filename\"].to_numpy(), test[\"bbox\"].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "### 2.1 Resizing & Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, bbox):\n",
    "\n",
    "    filename = path.decode(\"utf-8\")\n",
    "    path = f\"{dataset_path}\\{filename}\"\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if(bbox[0] > image.shape[1]):\n",
    "        bbox[0] = image.shape[1]\n",
    "    if(bbox[2] > image.shape[1]):\n",
    "        bbox[2] = image.shape[1]\n",
    "\n",
    "    if(bbox[1] > image.shape[0]):\n",
    "        bbox[1] = image.shape[0]\n",
    "    if(bbox[3] > image.shape[0]):\n",
    "        bbox[3] = image.shape[0]\n",
    "\n",
    "    for i in range(4):\n",
    "        if(bbox[i] < 0):\n",
    "            bbox[i] = 0\n",
    "        \n",
    "    # cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255,0,0), 1)\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "\n",
    "    transform = albumentations.Compose(\n",
    "        [albumentations.Resize(height=HEIGHT, width=WIDTH, always_apply=True)],\n",
    "        bbox_params=albumentations.BboxParams(format='pascal_voc'))\n",
    "\n",
    "    transformed = transform(image=image, bboxes=[np.concatenate([bbox,[0]])])\n",
    "    image, bbox = transformed[\"image\"], transformed[\"bboxes\"][0]\n",
    "\n",
    "\n",
    "\n",
    "    norm_image = tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "    x1, y1, x2, y2 = bbox[0]/WIDTH, bbox[1]/HEIGHT, bbox[2]/WIDTH, bbox[3]/HEIGHT\n",
    "    norm_bbox = np.array([x1, y1, x2, y2], dtype=np.float32)\n",
    "\n",
    "\n",
    "    return norm_image, norm_bbox\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Transforming data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(image, bbox):\n",
    "    image, bbox = tf.numpy_function(read_image, [image, bbox], [tf.float32, tf.float32])\n",
    "    image.set_shape((WIDTH, HEIGHT, 3))\n",
    "    bbox.set_shape((4))\n",
    "    return image, bbox\n",
    "\n",
    "# print(train_labels)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, list(train_bboxes)))\n",
    "train_dataset = train_dataset.map(parse).batch(5)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, list(test_bboxes)))\n",
    "test_dataset = test_dataset.map(parse).batch(5)\n",
    "\n",
    "# for X, bbox  in train_dataset:\n",
    "#     print(X.shape, bbox.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
    "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
    "    x any y are the coordinates of the top left corner of each box.\n",
    "    \n",
    "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(0,y_true.shape[0]):\n",
    "    \n",
    "        # set the types so we are sure what type we are using\n",
    "        y_true = y_true.astype(np.float32)\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_tleft = y_true[0,0]  # numpy index selection\n",
    "        y_boxTrue_tleft = y_true[0,1]\n",
    "        boxTrue_width = y_true[0,2]\n",
    "        boxTrue_height = y_true[0,3]\n",
    "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_tleft = y_pred[0,0]\n",
    "        y_boxPred_tleft = y_pred[0,1]\n",
    "        boxPred_width = y_pred[0,2]\n",
    "        boxPred_height = y_pred[0,3]\n",
    "        area_boxPred = (boxPred_width * boxPred_height)\n",
    "\n",
    "\n",
    "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
    "\n",
    "        # boxTrue\n",
    "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
    "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
    "\n",
    "        # boxPred\n",
    "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
    "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
    "\n",
    "\n",
    "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
    "\n",
    "        # boxInt - top left coords\n",
    "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
    "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
    "\n",
    "        # boxInt - bottom right coords\n",
    "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
    "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
    "\n",
    "        # Calculate the area of boxInt, i.e. the area of the intersection \n",
    "        # between boxTrue and boxPred.\n",
    "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
    "        \n",
    "        \n",
    "        # Version 2 revision\n",
    "        area_of_intersection = \\\n",
    "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
    "\n",
    "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
    "\n",
    "\n",
    "        # This must match the type used in py_func\n",
    "        iou = iou.astype(np.float32)\n",
    "        \n",
    "        # append the result to a list at the end of each loop\n",
    "        results.append(iou)\n",
    "    \n",
    "    # return the mean IoU score for the batch\n",
    "    return np.mean(results)\n",
    "\n",
    "\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    \n",
    "    # Note: the type float32 is very important. It must be the same type as the output from\n",
    "    # the python function above or you too may spend many late night hours \n",
    "    # trying to debug and almost give up.\n",
    "    \n",
    "    iou = tf.numpy_function(calculate_iou, [y_true, y_pred], tf.float32)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(DARKNET19_ARCHITECTURE, INPUT_SIZE)\n",
    "model.compile(optimizer=SGD(learning_rate=LEARNING_RATE), loss=\"huber_loss\", metrics=[IoU, \"accuracy\"])\n",
    "\n",
    "# checkpoint_path = \"/home/mushi/hand-gesture-project/models/model.hdf5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"models\\model3.hdf5\", verbose=1, save_weights_only=True, monitor='val_loss', save_freq='epoch'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "print(train_dataset)\n",
    "model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow(\"Test\", frame)\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(DARKNET19_ARCHITECTURE, INPUT_SIZE)\n",
    "model.load_weights(\"models/model3.hdf5\")\n",
    "model.compile(optimizer=SGD(learning_rate=LEARNING_RATE), loss=\"huber_loss\", metrics=[\"accuracy\"])\n",
    "# model.evaluate(test_dataset)\n",
    "\n",
    "# import random \n",
    "\n",
    "# # image = cv2.imread(f\"{dataset_path}\\data_4\\\\564_webcam_3.jpg\")\n",
    "# for i in range(10):\n",
    "#     name = random.choice(os.listdir(\"images\"))\n",
    "#     image = cv2.imread(f\"images\\{name}\")\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    x = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    x = tf.cast(x, tf.float32) / 255.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    pred_bbox = model.predict(x)\n",
    "    pred_bbox = pred_bbox[0]\n",
    "    # print( pred_bbox)\n",
    "\n",
    "    pred_x1 = int(pred_bbox[0] * image.shape[1])\n",
    "    pred_y1 = int(pred_bbox[1] * image.shape[0])\n",
    "    pred_x2 = int(pred_bbox[2] * image.shape[1])\n",
    "    pred_y2 = int(pred_bbox[3] * image.shape[0])\n",
    "\n",
    "    cv2.rectangle(image, (pred_x1, pred_y1, pred_x2, pred_y2), (255,0,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Test\", image)\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
